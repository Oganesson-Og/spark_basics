{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:3.75em;color:purple; font-style:bold\"><br>\n",
    "Spark Pipeline </p><br>\n",
    "                                \n",
    "Similar to scikit-learn, Pyspark has a pipeline API.\n",
    "\n",
    "A pipeline is very convenient to maintain the structure of the data. You push the data into the pipeline. Inside the pipeline, various operations are done, the output is used to feed the algorithm.\n",
    "\n",
    "For instance, one universal transformation in machine learning consists of converting a string to one hot encoder, i.e., one column by a group. One hot encoder is usually a matrix full of zeroes.\n",
    "\n",
    "The steps to transform the data are very similar to scikit-learn. You need to:\n",
    "\n",
    "Index the string to numeric\n",
    "Create the one hot encoder\n",
    "Transform the data\n",
    "Two APIs do the job: StringIndexer, OneHotEncoder\n",
    "\n",
    "First of all, you select the string column to index. The inputCol is the name of the column in the dataset. outputCol is the new name given to the transformed column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn.datasets import load_boston\n",
    "from pyspark import SQLContext\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "pd.pandas.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "sc = SparkSession.builder.appName('Kithavho').getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "data_frame = sc.read.csv('titanic_train.csv', header=True, inferSchema=True)\n",
    "data_frame.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol='Sex', outputCol='Sex_encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----------+\n",
      "|   Sex|Cabin|Sex_encoded|\n",
      "+------+-----+-----------+\n",
      "|  male| null|        0.0|\n",
      "|female|  C85|        1.0|\n",
      "|female| null|        1.0|\n",
      "|female| C123|        1.0|\n",
      "|  male| null|        0.0|\n",
      "|  male| null|        0.0|\n",
      "|  male|  E46|        0.0|\n",
      "|  male| null|        0.0|\n",
      "|female| null|        1.0|\n",
      "|female| null|        1.0|\n",
      "|female|   G6|        1.0|\n",
      "+------+-----+-----------+\n",
      "only showing top 11 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed = indexer.fit(data_frame).transform(data_frame)\n",
    "indexed.select('Sex', 'Cabin', 'Sex_encoded').show(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       Q|   77|\n",
      "|    null|    2|\n",
      "|       C|  168|\n",
      "|       S|  644|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame.groupBy('Embarked').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+\n",
      "|Embarked|Embarked_encoded|\n",
      "+--------+----------------+\n",
      "|       S|   (3,[0],[1.0])|\n",
      "|       C|   (3,[1],[1.0])|\n",
      "|       S|   (3,[0],[1.0])|\n",
      "|       S|   (3,[0],[1.0])|\n",
      "|       S|   (3,[0],[1.0])|\n",
      "|       Q|   (3,[2],[1.0])|\n",
      "|       S|   (3,[0],[1.0])|\n",
      "|       S|   (3,[0],[1.0])|\n",
      "|       S|   (3,[0],[1.0])|\n",
      "|       C|   (3,[1],[1.0])|\n",
      "|       S|   (3,[0],[1.0])|\n",
      "|       S|   (3,[0],[1.0])|\n",
      "|       S|   (3,[0],[1.0])|\n",
      "|       S|   (3,[0],[1.0])|\n",
      "|       S|   (3,[0],[1.0])|\n",
      "|       S|   (3,[0],[1.0])|\n",
      "|       Q|   (3,[2],[1.0])|\n",
      "|       S|   (3,[0],[1.0])|\n",
      "|       S|   (3,[0],[1.0])|\n",
      "|       C|   (3,[1],[1.0])|\n",
      "+--------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer_two = StringIndexer(inputCol='Embarked', outputCol='Embarked_indexed')\n",
    "indexed_two = indexer_two.fit(data_frame).transform(data_frame)\n",
    "one_hot = OneHotEncoder(dropLast=False, inputCol='Embarked_indexed', outputCol='Embarked_encoded')\n",
    "one_hotted = one_hot.fit(indexed_two).transform(indexed_two)\n",
    "one_hotted.select('Embarked', 'Embarked_encoded').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hotted = one_hotted.fillna({'Age': 35, 'Cabin': 'K7'})\n",
    "#one_hotted.show(5)\n",
    "one_hotted = one_hotted.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = false)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = false)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Embarked_indexed: double (nullable = false)\n",
      " |-- Embarked_encoded: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "one_hotted = one_hotted.drop('PassengerId', 'Name')\n",
    "one_hotted.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the pipeline\n",
    "You will build a pipeline to convert all the precise features and add them to the final dataset. The pipeline will have four operations, but feel free to add as many operations as you want.\n",
    "\n",
    "**Encode the categorical data\n",
    "\n",
    "**Index the label feature\n",
    "\n",
    "**Add continuous variable\n",
    "\n",
    "**Assemble the steps.\n",
    "\n",
    "**Each step is stored in a list named stages. This list will tell the VectorAssembler what operation to perform inside the pipeline.\n",
    "\n",
    "\n",
    "##### 1. Encode the categorical data\n",
    "\n",
    "This step is exaclty the same as the above example, except that you loop over all the categorical features.\n",
    "\n",
    "The stages empty list is for stages in your pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = ['Cabin', 'Sex', 'Ticket']\n",
    "stages = []\n",
    "\n",
    "for categorical in categoricals:\n",
    "    string_indexer = StringIndexer(inputCol=categorical, outputCol=categorical+'Index')\n",
    "    encoder = OneHotEncoder(inputCols=[string_indexer.getOutputCol()], outputCols=[categorical+'class_vec'])\n",
    "    stages+=[string_indexer, encoder]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Index the target variable\n",
    "\n",
    "Spark like most libraries do not accept string values for the target so if your dataset has string target then follow the following piece of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_string_index = StringIndexer(inputCol='Survived', outputCol='Survived_two')\n",
    "stages+=[label_string_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.) Add continuous variable\n",
    "\n",
    "Input cols of Vector Assembler takes alist of columns. You can create a new list containing all new columns.\n",
    "the code below will populate the list with encoded categorical features and continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = ['Pclass', 'SibSp', 'Parch', 'Fare']\n",
    "assembler_inputs = [c+'class_vec' for c in categoricals]+ continuous_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.) Assemble the steps\n",
    "\n",
    "Finally, you pass all the steps into the assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol='features')\n",
    "stages+=[assembler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all steps are ready we can push the data into the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_frame.fillna({'Age': 35, 'Cabin': 'K7'})\n",
    "#one_hotted.show(5)\n",
    "data_frame= data_frame.dropna()\n",
    "data_frame = data_frame.drop('PassengerId', 'Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pipeline\n",
    "pipeline = Pipeline(stages=stages)\n",
    "pipeline_model=pipeline.fit(data_frame)\n",
    "model = pipeline_model.transform(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = false)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = false)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- CabinIndex: double (nullable = false)\n",
      " |-- Cabinclass_vec: vector (nullable = true)\n",
      " |-- SexIndex: double (nullable = false)\n",
      " |-- Sexclass_vec: vector (nullable = true)\n",
      " |-- TicketIndex: double (nullable = false)\n",
      " |-- Ticketclass_vec: vector (nullable = true)\n",
      " |-- Survived_two: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one checks above the new dataset by the entry above, one can see that it includes all columns; old and new transformed ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the regressor/classifier depending with the problem\n",
    "Remember, if your working with an RDD, try converting it to a DataFrame as it is faster to process large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model dataset is already a dataFrame but to convert one can use toDF() or rdd to work in reverse. \n",
    "To pull out the new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = model.rdd.map(lambda x: (x['Survived_two'], DenseVector(x['features'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to create a train dataFrame you can use sqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train = input_data.toDF()\n",
    "type(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+--------------------+\n",
      "| Sexclass_vec|  Ticketclass_vec|            features|\n",
      "+-------------+-----------------+--------------------+\n",
      "|(1,[0],[1.0])|(679,[558],[1.0])|(830,[0,146,705,8...|\n",
      "|    (1,[],[])|(679,[612],[1.0])|(830,[103,759,826...|\n",
      "|    (1,[],[])|(679,[671],[1.0])|(830,[0,818,826,8...|\n",
      "|    (1,[],[])| (679,[46],[1.0])|(830,[19,193,826,...|\n",
      "|(1,[0],[1.0])|(679,[514],[1.0])|(830,[0,146,661,8...|\n",
      "|(1,[0],[1.0])|(679,[341],[1.0])|(830,[0,146,488,8...|\n",
      "|(1,[0],[1.0])|(679,[194],[1.0])|(830,[136,146,341...|\n",
      "|(1,[0],[1.0])| (679,[14],[1.0])|(830,[0,146,161,8...|\n",
      "|    (1,[],[])| (679,[28],[1.0])|(830,[0,175,826,8...|\n",
      "|    (1,[],[])| (679,[65],[1.0])|(830,[0,212,826,8...|\n",
      "+-------------+-----------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " model.select('Sexclass_vec', 'Ticketclass_vec','features').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a data_frame for quicker processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "|Survived_three|            features|\n",
      "+--------------+--------------------+\n",
      "|           0.0|[1.0,0.0,0.0,0.0,...|\n",
      "|           1.0|[0.0,0.0,0.0,0.0,...|\n",
      "+--------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = sqlContext.createDataFrame(input_data, ['Survived_three', 'features'])\n",
    "df_train.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------+\n",
      "|Survived_three|count(Survived_three)|\n",
      "+--------------+---------------------+\n",
      "|           0.0|                  429|\n",
      "|           1.0|                  278|\n",
      "+--------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = df_train.randomSplit([0.8, 0.2], seed=1234)\n",
    "train_data.groupby('Survived_three').agg({'Survived_three': 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(labelCol='Survived_three', featuresCol='features', maxIter=10, regParam=0.30)\n",
    "linearModel = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets print coefficients and intercepts of the linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.2811389063904822,0.520199534010019,-0.14796212404392703,0.0017792641670645115,-1.318150425556913,0.25303593189717877,0.6337081990786746,0.3977590396587624,0.6342784165722304,0.5526922459980488,0.6890704290420218,-0.03325509707351257,0.5515850528999431,0.7654130256775779,0.46280940182161134,0.47796339724192116,0.438579689658369,0.43095532129084413,0.540801772861677,0.5720049488240126,-0.5640444174702728,0.6592968596821579,0.0,-0.012500925715604017,0.7926848198337345,0.5380484162680356,-0.27980288458914576,-0.02312147654909265,-0.024269548214975317,0.6699750789157642,0.5496331426740162,0.577475675181702,0.5567793535736245,-0.5976083442535071,0.6621420783366327,0.6862201759151372,0.7831428630255016,0.9013615689498785,0.7956262774521466,0.7955952237285838,0.554508762668509,-0.00504816719683115,0.5556293123321875,0.7887151918795934,-0.46031615051583485,0.7535201382372211,-0.5711555927257356,-0.5783625304132612,0.5801229588238112,-0.5625261003933331,0.0,0.0,-0.5774521363990934,0.7891019504331049,0.7918885058588664,-0.5771518998494789,0.0,-0.5464931990755983,0.0,0.7891019504331049,-0.5654016007452247,0.48752523394941155,-0.5464931990755983,-0.5671156389715943,0.45358653078212685,-0.5885663417184228,-0.5647923616983995,-0.5628632314658674,0.5523673429917185,0.5763971797771703,0.7665118162609627,0.5750244552833647,0.0,0.5442111005360651,-0.5659026084935714,0.5337417221922452,0.5181254057852143,0.5403727304325014,0.49946998487912203,-0.5946940060711124,0.0,0.0,0.583803397619978,0.5771020247156212,0.0,0.792198307730696,0.0,0.0,-0.5692358400297256,-0.5680315234438318,0.7925081469901081,0.0,0.7422858976043548,0.39951260659098276,-0.9668447930349464,0.7926940685447897,-0.7877182454826824,0.5356301638550043,0.5439309731277052,0.41709015366781077,0.0,0.8781490676984527,-0.6760096511179258,0.5610174930935652,-0.5983607856823674,-0.5628632314658674,0.5632418275715463,-0.9676999560861628,-0.6759760072529407,0.7422858976043548,0.7657490777065776,0.5591940800892343,0.5469364493416213,0.789051324091881,0.5727504096706807,0.5639881697086074,-0.5665684579712256,0.5586114825144629,0.7925081469901081,-0.5674337114784435,0.5664811962810312,-0.875902196909773,0.7931776257528782,-0.5663951533208068,0.8552067711119022,-0.564975935368149,0.5591940800892343,0.5402491198592831,0.9115509004245331,0.7946470671785242,0.7946470671785242,-0.5714445677463099,0.5184611258655591,0.5587377371087254,-0.5628632314658674,0.5085479077917718,-0.5782793412595572,0.5483158308305578,0.7872734916295197,-0.5622731942073471,0.0,0.5282520225289681,-0.7517959397384518,0.5729956372650467,-0.4598383583750597,0.0,-0.7906780355071724,1.0404822279755117,-0.8180470125446633,-0.6333120017891812,-0.6233856305737735,-0.6990054029712819,-0.5903203626336265,-0.6372469994355093,-0.6562330849480238,0.520199534010019,0.1074535258619791,0.40139491792516746,-0.14796212404392703,1.0966452220306484,0.7346691063145027,-0.9210006418775131,-0.7515304359455143,-0.5462662394991457,0.5655323188679321,-0.8023004947722492,0.5416825982103743,0.5427093775971457,0.5544497725883772,0.3977590396587624,-0.6061279204677149,0.4588478924952052,0.45860302260261937,1.2783810972743899,-0.7991486518990492,1.081151786294363,-0.04644545370375565,0.7022785454140426,-0.5599490711879812,0.47707021046845427,0.47885886654066784,0.47707021046845427,0.7071987378012237,0.11667253937263809,0.47255523513119024,-0.020123424493147805,0.46423394211289754,-0.5783625304132612,0.5526922459980488,0.554508762668509,-0.012500925715604017,0.13229875665279037,0.9166666284780483,0.5720049488240126,0.7887151918795934,-0.9446996881948989,0.6862201759151372,0.5405462146877963,0.7654130256775779,0.5397409169121895,-0.00504816719683115,0.5142328920298408,0.6699750789157642,0.6890704290420218,0.26815452642300736,-0.02312147654909265,0.5496331426740162,0.0,0.9624926971605365,0.7535201382372211,0.9856493809764557,0.9879103552486052,0.23846447980353533,-0.6308285103893398,1.0272499736377743,-0.7951330671240412,0.24286744658050877,1.0036195575757654,0.9920185476745828,-0.6189734354395549,1.205217592533319,0.9907169842473866,-0.7380203189231658,0.9790181037679742,1.100522381401678,1.280053762811497,0.33848973925330683,1.4752882847338304,-0.8685672678608521,0.9001611962568767,-0.8904531380561427,-0.8957679246109099,1.45476080668635,-0.6313478822020935,1.3878496574444843,0.9937688253858683,0.3617260892516227,0.2726413165602689,-0.7035923252541788,-0.9784266837400197,-0.7263286219297527,-0.544856086745659,-0.5976083442535071,-0.5597085354573856,1.0778327419379934,-0.5503153941969998,1.3134743506834141,1.0962157271491297,0.8031354606457121,0.5567793535736245,-0.024269548214975317,-0.7478473657650369,0.3373474435526936,0.3366922790735098,0.9013615689498785,-0.5607293450379742,-0.555096035261325,-0.5513831559880767,-0.54329615000461,0.5249663257103513,0.3251982641737715,-0.630353003548602,1.4745925165049152,0.24503300867866432,0.5515850528999431,0.5587377371087254,0.43095532129084413,0.5095193941907952,-0.5946940060711124,0.8892690160125544,0.438579689658369,1.0451622425036318,0.5380484162680356,-0.5983607856823674,0.9819751169583069,0.41427464764201916,-0.6680968047493556,0.3369652468245192,-0.7419773945955445,-0.03325509707351257,0.7958288558621692,0.5586114825144629,-0.5671156389715943,0.0,0.7925081469901081,1.2847387974079123,0.0,1.2847387974079123,-0.5464931990755983,-0.6691657804579572,0.5750244552833647,-0.5464931990755983,0.0,0.7918885058588664,-0.7075868569501857,-0.5623609497826051,-0.564130025618365,-0.5628632314658674,0.0,0.7946470671785242,-0.5625261003933331,-0.7148818011795612,-0.564975935368149,-0.6760096511179258,-0.5885663417184228,-0.5680315234438318,-0.5628632314658674,-0.5771518998494789,-0.5665684579712256,0.5771020247156212,-0.8019694737792847,0.0,0.0,0.7891019504331049,-0.6949035014012844,1.2847387974079123,0.0,-0.6949035014012844,1.2807528469560165,-0.6949035014012844,0.5664811962810312,0.789051324091881,0.5801229588238112,0.7872734916295197,0.583803397619978,-0.5647923616983995,0.7926940685447897,0.5469364493416213,-0.6184610180160013,-0.5529827460192352,-0.5711555927257356,0.7891019504331049,0.0,-0.5628632314658674,0.7665118162609627,0.5523673429917185,1.081861931606443,1.081861931606443,1.081861931606443,-0.5532607577729935,0.7925081469901081,-0.5782793412595572,0.5727504096706807,0.577475675181702,0.0,-0.5654016007452247,0.7872952177434496,0.7946470671785242,-0.6691657804579572,0.792198307730696,0.0,-0.6184610180160013,-0.5532607577729935,-0.6189361037170309,-0.6178434827255449,-0.6184610180160013,0.0,1.0028873733159749,0.633128590602409,0.0,0.0,-0.6184610180160013,0.0,-0.6170360678940755,0.0,-0.6184610180160013,-0.6184610180160013,1.0033741149557638,0.0,1.0040068736434904,-0.6184610180160013,1.0033741149557638,-0.6126932005001915,-0.6189361037170309,0.0,1.0033741149557638,0.0,1.0026348977418273,0.0,-0.6061279204677149,0.0,0.0,1.0037148319095976,1.0033741149557638,1.3784721398196917,-0.6160863613156206,0.0,-0.6308285103893398,0.0,1.3784721398196917,0.8552067711119022,1.0004536021546475,-0.6184610180160013,0.0,0.6321572616307694,-0.6184610180160013,-0.9573753846714329,-0.6184610180160013,0.0,1.0033741149557638,-0.9564133928303029,0.0,-0.6184610180160013,1.467069022921177,-0.552496283148082,-0.552496283148082,1.4592740424700157,1.082386495607092,0.0,-0.5525001745586161,-0.552496283148082,-0.5525001745586161,-0.552496283148082,-0.5495212214931459,1.0823907259561045,0.0,-0.5311257674823664,1.4670645454586757,-0.552496283148082,1.0823907259561045,0.0,0.0,0.0,0.0,-0.552496283148082,1.4670645454586757,-0.5417866653247401,-0.5517667275048608,-0.5525001745586161,-0.5525001745586161,1.082386495607092,-0.868571324044666,-0.5427695767841271,0.0,0.0,-0.5427695767841271,0.0,0.0,0.0,0.6324926001921106,1.0033741149557638,-0.5990543574710641,-0.6160863613156206,0.0,1.0001728587430285,0.0,-0.6184610180160013,-0.6184610180160013,0.7935249382550187,-0.607985268183917,-0.6160863613156206,-0.6194112398565986,1.0095257383898362,-0.5888214753703087,0.9973460326157546,-0.6170360678940755,0.0,-0.6184610180160013,0.0,1.0821179689811724,-0.5344978886969619,0.0,-0.5186734965726955,1.1581159007088233,-0.5531449166371851,1.0712189556214868,-0.6160863613156206,1.4664827308951218,-0.5530059127517546,-0.5530059127517546,1.0033741149557638,-0.553828439087073,-0.5530985813442514,-0.8830924221951267,0.0,-0.553828439087073,-0.553828439087073,-0.553828439087073,-0.553828439087073,-0.553828439087073,-0.8830924221951267,-0.553828439087073,1.465536847843288,-0.5193397706994562,1.0550409041240363,-0.5525194463756926,-0.5532607577729935,-0.5532607577729935,-0.5536391700862257,0.0,1.0817821590677617,1.0815807130951647,1.081731797597405,1.0818241605226533,-0.882569215101773,1.081731797597405,1.081731797597405,0.0,1.081731797597405,-0.5529672707345853,-0.5529827460192352,1.081861931606443,0.0,-0.5529827460192352,-0.5538747847849974,-0.5532607577729935,0.0,-0.5532607577729935,-0.882482006344103,0.0,-0.5532607577729935,-0.5532607577729935,0.0,1.0942940201533364,0.0,-0.5541412852836828,-0.5541412852836828,-0.554604815899646,-0.554604815899646,1.464644455152097,-0.554604815899646,-0.554604815899646,1.464644455152097,-0.554604815899646,-0.554604815899646,-0.554604815899646,-0.5350010325721791,-0.5530059127517546,0.0,-0.5530059127517546,-0.5530059127517546,-0.5529827460192352,-0.5530059127517546,-0.5530059127517546,-0.5530059127517546,0.0,0.0,-0.5530059127517546,-0.5356682459849825,-0.5529827460192352,1.081861931606443,1.489699043060652,0.0,-0.882207907610002,0.0,0.0,-0.5530793060580242,-0.5530793060580242,-0.5530793060580242,1.0817569783344538,0.0,-0.4598383583750597,-0.45966414463691735,-0.45966414463691735,-0.5531178567454418,-0.5531178567454418,-0.5531178567454418,-0.5531178567454418,-0.5531178567454418,-0.5531178567454418,-0.5531178567454418,-0.5527471961376402,-0.5527471961376402,-0.5531178567454418,-0.5531178567454418,-0.5531178567454418,-0.5531178567454418,-0.5531178567454418,0.0,-0.5531178567454418,-0.5531178567454418,-0.5531178567454418,0.0,-0.5531178567454418,-0.5531178567454418,-0.5531178567454418,-0.5531178567454418,0.0,-0.5531178567454418,-0.5531178567454418,-0.5531178567454418,-0.883279262959478,-0.553828439087073,1.4663539712515763,-0.5531178567454418,-0.5531178567454418,-0.5531178567454418,1.0809218822289353,0.0,-0.5531178567454418,-0.5531178567454418,-0.5531178567454418,-0.5531178567454418,-0.5531178567454418,-0.5531178567454418,-0.5531178567454418,0.0,0.0,-0.5531178567454418,-0.5427916250763326,0.0,-0.5357407227792973,0.0,-0.5530793060580242,1.4664605600683014,0.0,-0.5530251875999495,-0.5530251875999495,1.4664605600683014,1.103948117454139,-0.5530793060580242,-0.5350087176377701,-0.5530793060580242,-0.5530251875999495,-0.5527703611761374,-0.5433392718656591,-0.882286850232526,0.0,1.4663983118581763,1.0818787523264493,1.0818787523264493,-0.5529595794530678,-0.5525194463756926,0.0,-0.5532607577729935,-0.5592436249132262,0.0,0.0,-0.5532607577729935,-0.5532607577729935,-0.5532607577729935,-0.882182988485702,-0.8958559135137699,-0.882182988485702,-0.5529827460192352,-0.5520562137117458,-0.8811860793386664,-0.5601721281621165,1.4665093786844257,-0.5356453685860273,0.0,0.0,-0.5529634714245557,-0.5522414987116852,-0.5529750547008188,-0.552971162715354,0.0,-0.5529827460192352,-0.5663951533208068,-0.5674337114784435,-0.5529827460192352,1.081861931606443,0.0,-0.5529827460192352,1.081861931606443,1.081861931606443,0.0,-0.5529827460192352,-0.5529827460192352,-0.5683934949047311,-0.5529827460192352,-0.5532607577729935,-0.5532607577729935,-0.5525194463756926,-0.5532607577729935,-0.54329615000461,-0.882182988485702,1.4665093786844257,0.0,-0.5529827460192352,1.0956088820366767,1.0741926215501323,-0.5532607577729935,-0.552156544201924,0.0,-0.884014073131925,-0.863984650397791,0.0,0.0,-0.561285232261305,-0.5622731942073471,-0.546845337167758,-0.546845337167758,1.4661230029143721,0.0,-0.6943693160495552,0.0,-0.5543498659884802,-0.5538207457648272,-0.554589332925313,-0.8636379399397865,-0.8849396635453619,-0.8842631262066067,1.4661896167968258,-0.5535503787202383,-0.5536159988282203,0.0,-0.5532607577729935,-0.5532607577729935,-0.5532607577729935,-0.5532607577729935,-0.5532607577729935,-0.5532607577729935,0.0,0.0,-0.5351878586906718,-0.5525194463756926,0.0,-0.5525194463756926,0.0,-0.5532607577729935,-0.5532607577729935,1.4661896167968258,-0.5532607577729935,-0.5525194463756926,1.4661896167968258,-0.5529672707345853,0.0,0.0,-0.5743895983761244,0.0,0.0,1.467157826958005,0.0,-0.5517783064461536,0.0,1.08236554530591,-0.6160863613156206,-0.6160863613156206,-0.6160863613156206,-0.6160863613156206,0.0,0.6346027488038559,-0.6160863613156206,1.0058077727982309,-0.6160863613156206,1.000696984461605,0.0,-0.5527974181523548,-0.5598006979906439,-0.6160863613156206,1.0820633772502375,-0.5659026084935714,0.0,1.0058077727982309,-0.5525773551771894,-0.694296475221157,0.7945159457402837,0.7944206908847922,0.7944993280506573,0.7944993280506573,0.5632418275715463,-0.6759760072529407,0.871180211306437,-0.5774521363990934,0.5639881697086074,-0.7877182454826824,-0.5692358400297256,-0.7362252460022796,0.5610174930935652,0.0,0.0,0.0,0.0,-0.7172208432181111,0.5763971797771703,-0.6960407472742829,0.0,0.5483158308305578,0.7657490777065776,-0.5544657498693993,-0.5532607577729935,-0.5527974181523548,-0.6180097337148639,-0.5533611258824855,1.3810758160027838,1.004347587471937,-0.6126932005001915,1.0123676187547574,0.7927611588602562,0.0,0.0,1.3775743081409568,0.0,-0.6143145641728784,-0.829328748437028,-0.6177722342294276,0.0,-0.5523341452479856,-0.5523341452479856,-0.5523341452479856,-0.5523341452479856,0.0,0.0,0.9115509004245331,0.0,-0.5524036319132255,0.0,-0.5532607577729935,0.0,0.0,-0.5532607577729935,-0.5532607577729935,1.4661896167968258,0.0,1.4663228478467434,-0.5524036319132255,-0.5524036319132255,-0.5524036319132255,-0.5531449166371851,1.489538770945948,1.4663228478467434,1.4663228478467434,1.4663228478467434,-0.5531449166371851,-0.5531449166371851,-0.5531449166371851,-0.8621021203939395,1.0816856664773402,1.0816856664773402,-0.8823574186552103,1.3810758160027838,1.0058077727982309,-0.6160863613156206,-0.8819836291519583,-0.5714445677463099,-0.1871710148058925,-0.04136240841249215,0.01708163733888955,0.0020866070906501795]\n",
      "Intercepts: 0.522533282141282\n"
     ]
    }
   ],
   "source": [
    "print('Coefficients: '+ str(linearModel.coefficients))\n",
    "print('Intercepts: '+ str(linearModel.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.)  Train and evaluate a model\n",
    "\n",
    "to generate prediction for your test set,\n",
    "\n",
    "You can use linearModel with transform() method on test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = linearModel.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print the elements in predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived_three: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can see the label, prediction and the probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+--------------------+\n",
      "|Survived_three|prediction|         probability|\n",
      "+--------------+----------+--------------------+\n",
      "|           0.0|       0.0|[0.69285197803288...|\n",
      "|           0.0|       0.0|[0.59266210850317...|\n",
      "|           0.0|       0.0|[0.59668567630403...|\n",
      "|           0.0|       0.0|[0.59806580809939...|\n",
      "|           0.0|       0.0|[0.71609531823137...|\n",
      "|           0.0|       0.0|[0.61190235960121...|\n",
      "|           0.0|       0.0|[0.70780567179051...|\n",
      "|           0.0|       0.0|[0.59459792507724...|\n",
      "|           0.0|       1.0|[0.31325609359218...|\n",
      "|           0.0|       0.0|[0.81338883913905...|\n",
      "|           0.0|       1.0|[0.30860478356656...|\n",
      "|           0.0|       1.0|[0.31905227992710...|\n",
      "|           0.0|       1.0|[0.28086900041362...|\n",
      "|           0.0|       1.0|[0.49173058797778...|\n",
      "|           0.0|       0.0|[0.63791093631553...|\n",
      "|           0.0|       0.0|[0.54376228840651...|\n",
      "|           0.0|       0.0|[0.57525427913056...|\n",
      "|           0.0|       0.0|[0.58205747504491...|\n",
      "|           0.0|       0.0|[0.58442859643939...|\n",
      "|           0.0|       0.0|[0.57535410173069...|\n",
      "+--------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected = predictions.select('Survived_three', 'prediction', 'probability')\n",
    "selected.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to look at the accuracy metric to see how well the model performs. Currently there is no API to compute the accuracy measure in Spark.\n",
    "The default value is the ROC.\n",
    "\n",
    "Lets construct an accuracy measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = predictions.select('Survived_three', 'prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------+\n",
      "|Survived_three|count(Survived_three)|\n",
      "+--------------+---------------------+\n",
      "|           0.0|                  120|\n",
      "|           1.0|                   62|\n",
      "+--------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm.groupby('Survived_three').agg({'Survived_three': 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|              140|\n",
      "|       1.0|               42|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm.groupby('prediction').agg({'prediction': 'count'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the accuracy we can use the filter function where Survived matched with predictions then divide by total count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model accurcay is 74.72527472527473\n"
     ]
    }
   ],
   "source": [
    "acc = cm.filter(cm.Survived_three==cm.prediction).count()/cm.count()\n",
    "print(f'The model accurcay is {acc*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can wrap everything in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_m(model):\n",
    "    predictions = model.transform(test_data)\n",
    "    cm = predictions.select('Survived_three', 'prediction')\n",
    "    acc = cm.filter(cm.Survived_three==cm.prediction).count()/cm.count()\n",
    "    print(f'The model accurcay is {acc*100}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model accurcay is 74.72527472527473\n"
     ]
    }
   ],
   "source": [
    "accuracy_m(linearModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the metric areaUnderROC, is 0.8558467741935487\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction', labelCol='Survived_three' )\n",
    "print(f'For the metric {evaluator.getMetricName()}, is {evaluator.evaluate(predictions)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6) Hyperparameter turning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create paramGrid for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = (ParamGridBuilder().addGrid(lr.regParam, [0.01, 0.5]).build())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally you use five-fold crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model took 169.82509541511536 to train\n"
     ]
    }
   ],
   "source": [
    "from time import *\n",
    "start_time = time()\n",
    "\n",
    "cv = CrossValidator(estimator = lr, estimatorParamMaps = paramGrid, evaluator=evaluator, numFolds=5)\n",
    "cvModel = cv.fit(train_data)\n",
    "end_time = time()\n",
    "elapsed_time = end_time-start_time\n",
    "print(f'The model took {elapsed_time} to train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model accurcay is 77.47252747252747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_7297c5e62178', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 2,\n",
       " Param(parent='LogisticRegression_7297c5e62178', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0,\n",
       " Param(parent='LogisticRegression_7297c5e62178', name='family', doc='The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial'): 'auto',\n",
       " Param(parent='LogisticRegression_7297c5e62178', name='featuresCol', doc='features column name.'): 'features',\n",
       " Param(parent='LogisticRegression_7297c5e62178', name='fitIntercept', doc='whether to fit an intercept term.'): True,\n",
       " Param(parent='LogisticRegression_7297c5e62178', name='labelCol', doc='label column name.'): 'Survived_three',\n",
       " Param(parent='LogisticRegression_7297c5e62178', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       " Param(parent='LogisticRegression_7297c5e62178', name='predictionCol', doc='prediction column name.'): 'prediction',\n",
       " Param(parent='LogisticRegression_7297c5e62178', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'): 'probability',\n",
       " Param(parent='LogisticRegression_7297c5e62178', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'): 'rawPrediction',\n",
       " Param(parent='LogisticRegression_7297c5e62178', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n",
       " Param(parent='LogisticRegression_7297c5e62178', name='standardization', doc='whether to standardize the training features before fitting the model.'): True,\n",
       " Param(parent='LogisticRegression_7297c5e62178', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5,\n",
       " Param(parent='LogisticRegression_7297c5e62178', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0).'): 1e-06}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_m(cvModel)\n",
    "best_model = cvModel.bestModel\n",
    "best_model.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "save() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-5373ad447b57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdtemp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: save() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "import os, tempfile\n",
    "\n",
    "path = tempfile.mkdtemp()\n",
    "best_model.save(sc, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
